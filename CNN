import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler

# Load the dataset
data = pd.read_csv("pimadiabetes.csv")

# Split the data
X = data.drop(columns=["Outcome"])
Y = data["Outcome"]

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=None)

# Scale the data
scaler = StandardScaler()
X = scaler.fit_transform(X)

ni = 8 # number of features
ns = 10 # number of time steps
nf = 128 # number of filters
nk = 5 # size of kernel
stride = 1 # stride length
padding = 'same' # padding mode
dilation = 1 # dilation factor

# Define the CNN model
model_cnn = tf.keras.Sequential([
    tf.keras.layers.Conv1D(filters = nf, kernel_size = nk, strides = stride, padding = padding, activation = 'relu', input_shape = (ni, 1)),
    tf.keras.layers.MaxPooling1D(pool_size = 3),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.05),
    tf.keras.layers.Dense(units = 1, activation = 'sigmoid')
])

# Calculate the number of zeros added by the padding
if padding == 'same':
    npad = int((nk - 1) / 2)
elif padding == 'valid':
    npad = 0
else:
    raise ValueError("Unknown padding mode")

# Compile the model
model_cnn.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])

# Define the K-fold cross-validator
kfold = KFold(n_splits=10, shuffle=True, random_state=None)

accuracy_scores = []
for train_idx, test_idx in kfold.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    Y_train, Y_test = Y[train_idx], Y[test_idx]

    # Reshape the data for the CNN model
    X_train = np.reshape(X_train, (X_train.shape[0], ni, 1))
    X_test = np.reshape(X_test, (X_test.shape[0], ni, 1))

    # Define the early stopping callback
    early_stopping = tf.keras.callbacks.EarlyStopping(patience=150, monitor='val_loss', restore_best_weights=True)

    # Train the CNN model
    history_cnn = model_cnn.fit(X_train, Y_train, epochs=200, batch_size=64, 
                                validation_data=(X_test, Y_test), verbose=0, callbacks=[early_stopping]) # type: ignore
    
    # Evaluate the CNN model on the test data
    loss_cnn, acc_cnn = model_cnn.evaluate(X_test, Y_test)
    accuracy_scores.append(acc_cnn)

# Calculate mean and standard deviation of the accuracy scores
mean_accuracy = np.mean(accuracy_scores)
std_accuracy = np.std(accuracy_scores)

# Calculate the complexity of the model
CCNN = ni * nf * nk * (ns + 2 * npad - dilation * (nk - 1) - 1 / stride + 1)
print("Complexity of the 1-D CNN model:", CCNN)

# Accuracy of CNN model with cross-validation
print("Accuracy of CNN model with cross-validation: {:.2f}%".format(mean_accuracy * 100, std_accuracy * 100)) # type: ignore
